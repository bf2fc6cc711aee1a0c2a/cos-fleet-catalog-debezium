{
  "connector_type" : {
    "id" : "debezium-sqlserver",
    "kind" : "ConnectorType",
    "href" : "/api/connector_mgmt/v1/kafka_connector_types/debezium-sqlserver-2.1.4.Final",
    "name" : "Debezium SQLServer Connector",
    "version" : "2.1.4.Final",
    "channels" : [ "stable" ],
    "description" : "Captures row-level changes in the schemas of a SQL Server database.",
    "labels" : [ "source", "debezium", "sqlserver", "2.1.4.Final" ],
    "capabilities" : [ "data_shape" ],
    "icon_href" : "http://example.com/images/debezium-sqlserver-2.1.4.Final.png",
    "schema" : {
      "title" : "Debezium SQLServer Connector",
      "required" : [ "topic.prefix", "database.hostname" ],
      "type" : "object",
      "properties" : {
        "topic.prefix" : {
          "title" : "Topic prefix",
          "description" : "Topic prefix that identifies and provides a namespace for the particular database server/cluster is capturing changes. The topic prefix should be unique across all other connectors, since it is used as a prefix for all Kafka topic names that receive events emitted by this connector. Only alphanumeric characters, hyphens, dots and underscores must be accepted.",
          "type" : "string",
          "nullable" : false,
          "x-name" : "topic.prefix",
          "x-category" : "CONNECTION"
        },
        "database.hostname" : {
          "title" : "Hostname",
          "description" : "Resolvable hostname or IP address of the database server.",
          "type" : "string",
          "nullable" : false,
          "x-name" : "database.hostname",
          "x-category" : "CONNECTION"
        },
        "database.port" : {
          "format" : "int32",
          "title" : "Port",
          "description" : "Port of the database server.",
          "default" : 1433,
          "type" : "integer",
          "x-name" : "database.port",
          "x-category" : "CONNECTION"
        },
        "database.user" : {
          "title" : "User",
          "description" : "Name of the database user to be used when connecting to the database.",
          "type" : "string",
          "x-name" : "database.user",
          "x-category" : "CONNECTION"
        },
        "database.password" : {
          "title" : "Password",
          "description" : "Password of the database user to be used when connecting to the database.",
          "oneOf" : [ {
            "format" : "password",
            "description" : "Password of the database user to be used when connecting to the database.",
            "type" : "string"
          }, {
            "description" : "An opaque reference to the password.",
            "type" : "object",
            "properties" : { },
            "additionalProperties" : true
          } ],
          "x-name" : "database.password",
          "x-category" : "CONNECTION"
        },
        "database.names" : {
          "format" : "list,regex",
          "title" : "Databases",
          "description" : "The names of the databases from which the connector should capture changes",
          "type" : "string",
          "x-name" : "database.names",
          "x-category" : "CONNECTION"
        },
        "table.include.list" : {
          "format" : "list,regex",
          "title" : "Include Tables",
          "description" : "The tables for which changes are to be captured",
          "type" : "string",
          "x-name" : "table.include.list",
          "x-category" : "FILTERS"
        },
        "table.exclude.list" : {
          "format" : "list,regex",
          "title" : "Exclude Tables",
          "description" : "A comma-separated list of regular expressions that match the fully-qualified names of tables to be excluded from monitoring",
          "type" : "string",
          "x-name" : "table.exclude.list",
          "x-category" : "FILTERS"
        },
        "column.include.list" : {
          "format" : "list,regex",
          "title" : "Include Columns",
          "description" : "Regular expressions matching columns to include in change events",
          "type" : "string",
          "x-name" : "column.include.list",
          "x-category" : "FILTERS"
        },
        "column.exclude.list" : {
          "format" : "list,regex",
          "title" : "Exclude Columns",
          "description" : "Regular expressions matching columns to exclude from change events",
          "type" : "string",
          "x-name" : "column.exclude.list",
          "x-category" : "FILTERS"
        },
        "snapshot.mode" : {
          "title" : "Snapshot mode",
          "description" : "The criteria for running a snapshot upon startup of the connector. Options include: 'initial' (the default) to specify the connector should run a snapshot only when no offsets are available for the logical server name; 'schema_only' to specify the connector should run a snapshot of the schema when no offsets are available for the logical server name. ",
          "default" : "initial",
          "enum" : [ "initial_only", "initial", "schema_only" ],
          "type" : "string",
          "x-name" : "snapshot.mode",
          "x-category" : "CONNECTOR_SNAPSHOT"
        },
        "decimal.handling.mode" : {
          "title" : "Decimal Handling",
          "description" : "Specify how DECIMAL and NUMERIC columns should be represented in change events, including: 'precise' (the default) uses java.math.BigDecimal to represent values, which are encoded in the change events using a binary representation and Kafka Connect's 'org.apache.kafka.connect.data.Decimal' type; 'string' uses string to represent values; 'double' represents values using Java's 'double', which may not offer the precision but will be far easier to use in consumers.",
          "default" : "precise",
          "enum" : [ "string", "double", "precise" ],
          "type" : "string",
          "x-name" : "decimal.handling.mode",
          "x-category" : "CONNECTOR"
        },
        "message.key.columns" : {
          "title" : "Columns PK mapping",
          "description" : "A semicolon-separated list of expressions that match fully-qualified tables and column(s) to be used as message key. Each expression must match the pattern '<fully-qualified table name>:<key columns>', where the table names could be defined as (DB_NAME.TABLE_NAME) or (SCHEMA_NAME.TABLE_NAME), depending on the specific connector, and the key columns are a comma-separated list of columns representing the custom key. For any table without an explicit key configuration the table's primary key column(s) will be used as message key. Example: dbserver1.inventory.orderlines:orderId,orderLineId;dbserver1.inventory.orders:id",
          "type" : "string",
          "x-name" : "message.key.columns",
          "x-category" : "CONNECTOR_ADVANCED"
        },
        "query.fetch.size" : {
          "format" : "int32",
          "title" : "Query fetch size",
          "description" : "The maximum number of records that should be loaded into memory while streaming. A value of '0' uses the default JDBC fetch size.",
          "default" : 0,
          "type" : "integer",
          "x-name" : "query.fetch.size",
          "x-category" : "ADVANCED"
        },
        "max.batch.size" : {
          "format" : "int32",
          "title" : "Change event batch size",
          "description" : "Maximum size of each batch of source records. Defaults to 2048.",
          "default" : 2048,
          "type" : "integer",
          "x-name" : "max.batch.size",
          "x-category" : "ADVANCED"
        },
        "max.queue.size" : {
          "format" : "int32",
          "title" : "Change event buffer size",
          "description" : "Maximum size of the queue for change events read from the database log but not yet recorded or forwarded. Defaults to 8192, and should always be larger than the maximum batch size.",
          "default" : 8192,
          "type" : "integer",
          "x-name" : "max.queue.size",
          "x-category" : "ADVANCED"
        },
        "data_shape" : {
          "type" : "object",
          "additionalProperties" : false,
          "properties" : {
            "key" : {
              "title" : "Kafka Message Key Format",
              "description" : "The serialization format for the Kafka message key.",
              "x-name" : "data_shape.key",
              "x-category" : "CONNECTOR",
              "$ref" : "#/$defs/serializer"
            },
            "value" : {
              "title" : "Kafka Message Value Format",
              "description" : "The serialization format for the Kafka message value.",
              "x-name" : "data_shape.value",
              "x-category" : "CONNECTOR",
              "$ref" : "#/$defs/serializer"
            }
          }
        }
      },
      "additionalProperties" : true,
      "x-connector-id" : "sqlserver",
      "x-version" : "2.1.4.Final",
      "x-className" : "io.debezium.connector.sqlserver.SqlServerConnector",
      "$defs" : {
        "serializer" : {
          "type" : "string",
          "enum" : [ "JSON", "JSON without schema" ],
          "default" : "JSON"
        }
      }
    }
  },
  "channels" : {
    "stable" : {
      "shard_metadata" : {
        "connector_revision" : 5,
        "operators" : [ {
          "type" : "debezium-connector-operator",
          "version" : "[1.0.0,2.0.0)"
        } ],
        "connector_type" : "source",
        "connector_class" : "io.debezium.connector.sqlserver.SqlServerConnector",
        "container_image" : "quay.io/rhoas/rhoc-connector-debezium-sqlserver@sha256:4f2783ff04ee35f2c64e965e31576ff647f4c12301963e7108e4c74d1d651298"
      }
    }
  }
}